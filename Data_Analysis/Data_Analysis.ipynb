{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution:\n",
    "\n",
    "##### Area under the curve\n",
    "= probability of randomly selecting less than the x value on the x axis = proportion of the sample/populaion with scores less than x.\n",
    "\n",
    "1 Standard Deviation = 68%\n",
    "2 Standard Deviation = 95%\n",
    "3 Standard Deviation = 98%\n",
    "\n",
    "Having the equation of the probability density function (PDF), we can use calculus to find the area under the curve between any two values or between a value and negative infinity. But, mathematicians have done that alrady for us and put these values in a table, called Z-Table.\n",
    "\n",
    "A value in the X axis (called Z score) tells us what is the standard deviation of that point. It can be calculated like this: z= (x value - value of 1 Std Dev) / Std Dev.\n",
    "\n",
    "The Z-Table tells us the proportion less than the Z score, in the standard normal curve.\n",
    "\n",
    "f(x)=(e^-(x-mu)^2 / (2*sigma)^2) / sigma raiz(2*pi)\n",
    "\n",
    "### Z-Test\n",
    "\n",
    "Z-test is used when we know the population parameters mu (mean) and sigma (Std Dev). But this case is rare to find in real scenarios. We often have samples, which we must use to draw all our conclusions.\n",
    "\n",
    "Normally samples are used in real scenarios. Some tests are done to check how different a sample mean is from the population mean or also to check how different two samples are from each other.\n",
    "\n",
    "When we work with samples, we have to estimate the population standard deviation using the sample standard deviation with Bessel's correction. \n",
    "\n",
    "Bessel's correction: S = raiz((sum(xi-xmean)^2) / n-1)\n",
    "\n",
    "Normally to find out how typical or atypical a sample mean is, we would find its location on the distribution of sample means, called the Sampling Distribution. Then we can determine the shape and the parameters of the Sampling Distribution, if we know the population parameters.\n",
    "\n",
    "##### Sampling Distribution: \n",
    "\n",
    "Very rarely is possible to access the whole population; instead of that, samples are done in order to study the distibution of the data and so on. \n",
    "\n",
    "###### Important fact: the distribution of the sample means is normal; and the mean of all these sample means is equal to the population mean.\n",
    "\n",
    "The idea is the following: if we take a random sample, we would need to find out where on the distribution of sample means, that particular random sample will lie. For that we need the mean and the std dev of the random sample and the mean and std deviation of the distribution of the sample means.\n",
    "\n",
    "Now, if you take all the possible samples of a population and you can calculate the mean of all the sample means, and also the Standard Deviation of the population and the standard error, and if you calcaulate the ratio of sigma (std dev) and SE (Standard Error) (sigma/SE) you get as a result the sqrt(sample size).\n",
    "\n",
    "This means that the standard deviation of the population (sigma) and the standard deviation of the sampling distribution (SE) have a relationship, and it is: SE = Sigma/sqrt(n)\n",
    "\n",
    "This is called the Central Limit Theorem. Because of this theorem we could have a population distribution of any shape, and lets say we take hundreds of sample from it and calculate the mean of each of them, and if we plot the distribution of the means, we get something which is relatively normal distributed, with a Std Deviation SE = sigma/sqrt(n). \n",
    "\n",
    "sigma = population standard deviation\n",
    "SE = Standard Error = Standard Deviation of distribution of sample means = std dev of sampling distribution\n",
    "\n",
    "mean = u or mu\n",
    "Standard Error = sigma / sqrt(n)\n",
    "\n",
    "Remember that for any sample mean, we can find where it falls on the Sampling Distribution by standardizing. In other words finding the Z-score of the sample mean. We find the difference between the sample mean and u (mu=population mean) and divide by the standard error.\n",
    "\n",
    "Z = (mean difference (sample mean - mu)) / SE\n",
    "\n",
    "##### T-Distribution (t-statistics = Student's t)\n",
    " \n",
    "But SE depends on the sample, we cannot longer use sigma if we have a sample. Therefore, we end up with a new distribution that is more prone to error. This is called the T-distribution. Since it is more prone to error, this is more spread out and thicker in the tails than a normal distribution.\n",
    "\n",
    "##### Z-score\n",
    "\n",
    "Z-score is basically the number of standard deviations any value is away from the mean. Therefore, we can convert any value in a normal distribution to a Z-score. When we do that, we standardize the distribution. \n",
    "\n",
    "Conceptually, what the Z-score makes is that it shifts the sample distribution all the way over to zero, because we are substracting the population mean. That means that the mean of the standardized distribution will be now in 0. When we divide by the standard deviation, we then change the shape of the distribution. The Z-score for the standard deviation also changes and is now: Z = (sigma-0) / sigma = 1.\n",
    "\n",
    "To recap, when we have any normal distribution, we can standardize it by first substracting the mean, shifting it to 0 and then dividing by the standard deviation, which makes the standard deviation equals to 1. This is called the standard normal distribution with mean 0 and standard deviation 1.\n",
    "\n",
    "##### Degrees of Freedom\n",
    "\n",
    "Degrees of freedom are the number of pieces of information that can be freely varied without violating any given restriction.\n",
    "\n",
    "It is defined as the number of posibilities you can choose. For example, if you have 5 numbers and the addition of them should be 10, then the degrees of freedom is 4, since you can choose ramdomly 4 numbers, but the 5th one is forced, so that the addition of all of them is 10. Which means the degrees of freedom in a generalized way is n-1.\n",
    "\n",
    "For a matriz n x n, the degrees of freedom is (n-1) x (n-1) = (n-1)^2\n",
    "\n",
    "As the degrees of freedom increases, the t-distribution better approximates the normal distribution.\n",
    "\n",
    "##### T-Table\n",
    "\n",
    "T-table is composed by the row index = \"Degrees of Freedom\" and the column header = \"the probability value that a random chosen value is on the right tail\". \n",
    "On the x-axis of the t-distribution we have the t-values instead of the z-values.\n",
    "T-table only care about the critical values (values on the tails). \n",
    "\n",
    "For example, lets say we have a t-distribution and we want to know the t critical value such that 10% of the values are in the right tail, or a proportion of 0.1. Let's say that our sample size is 10, that means our degrees of freedom is 9. So, we can then use the t-table to find out that value, looking at the row of 9 degrees of freedom and the column of 0.1 proportion. Where the column and the row meet, that is the t-value.\n",
    "\n",
    "#### Note:\n",
    "\n",
    "T-test aims at accepting or rejecting a null hypothesis. A null hypothesis is generally a statement that we are trying to disprove by running our test.\n",
    "\n",
    "Student's t-test: used to check if two sample means are significantly different. It assumes both samples have equal variance.\n",
    "\n",
    "Welch's t-test: it is also used to check if two sample means are significantly different, but it does NOT assume that both samples have equal variance.\n",
    "\n",
    "The null hypothesis for the test is that the means are equal.\n",
    "The alternate hypothesis for the test is that means are not equal.\n",
    "Experts say that it is better always to use Welch's t-test, since it is more reliable. Also, even if the variance of the two samples is equal, Welch' t-test yields the same result than t-test.\n",
    "\n",
    "All hypothesis tests ultimately use a p-value to weigh the strength of the evidence (what the data are telling you about the population). The p-value is a number between 0 and 1 and interpreted in the following way:\n",
    "\n",
    "##### A small p-value (typically â‰¤ 0.05) indicates strong evidence against the null hypothesis, so you reject the null hypothesis.\n",
    "\n",
    "##### A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject the null hypothesis.\n",
    "\n",
    "##### p-values very close to the cutoff (0.05) are considered to be marginal (could go either way). Always report the p-value so your readers can draw their own conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Performs a t-test on two sets of baseball data (left-handed and right-handed hitters).\n",
    "\n",
    "#### Null Hypothesis: the mean of left hand batters (sample or population 1) is equal than the mean of right hand batters (sample or population 2).\n",
    "\n",
    "You will be given a csv file that has three columns.  A player's\n",
    "name, handedness (L for lefthanded or R for righthanded) and their\n",
    "career batting average (called 'avg'). \n",
    "\n",
    "Write a function that will read that the csv file into a pandas data frame,\n",
    "and run Welch's t-test on the two cohorts defined by handedness.\n",
    "\n",
    "One cohort should be a data frame of right-handed batters. And the other\n",
    "cohort should be a data frame of left-handed batters.\n",
    "\n",
    "We have included the scipy.stats library to help you write\n",
    "or implement Welch's t-test:\n",
    "http://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "\n",
    "With a significance level of 95%, if there is no difference\n",
    "between the two cohorts, return a tuple consisting of\n",
    "True, and then the tuple returned by scipy.stats.ttest.  \n",
    "\n",
    "If there is a difference, return a tuple consisting of\n",
    "False, and then the tuple returned by scipy.stats.ttest.\n",
    "\n",
    "For example, the tuple that you return may look like:\n",
    "(True, (9.93570222, 0.000023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball=pandas.read_csv('baseball_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>handedness</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>avg</th>\n",
       "      <th>HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon Hyde</td>\n",
       "      <td>R</td>\n",
       "      <td>75</td>\n",
       "      <td>210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carey Selph</td>\n",
       "      <td>R</td>\n",
       "      <td>69</td>\n",
       "      <td>175</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philip Nastu</td>\n",
       "      <td>L</td>\n",
       "      <td>74</td>\n",
       "      <td>180</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kent Hrbek</td>\n",
       "      <td>L</td>\n",
       "      <td>76</td>\n",
       "      <td>200</td>\n",
       "      <td>0.282</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Risley</td>\n",
       "      <td>R</td>\n",
       "      <td>74</td>\n",
       "      <td>215</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wood</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steve Gajkowski</td>\n",
       "      <td>R</td>\n",
       "      <td>74</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rick Schu</td>\n",
       "      <td>R</td>\n",
       "      <td>72</td>\n",
       "      <td>170</td>\n",
       "      <td>0.246</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tom Brown</td>\n",
       "      <td>R</td>\n",
       "      <td>73</td>\n",
       "      <td>170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tom Browning</td>\n",
       "      <td>L</td>\n",
       "      <td>73</td>\n",
       "      <td>190</td>\n",
       "      <td>0.153</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name handedness height weight    avg   HR\n",
       "0     Brandon Hyde          R     75    210  0.000    0\n",
       "1      Carey Selph          R     69    175  0.277    0\n",
       "2     Philip Nastu          L     74    180  0.040    0\n",
       "3       Kent Hrbek          L     76    200  0.282  293\n",
       "4      Bill Risley          R     74    215  0.000    0\n",
       "5             Wood        NaN                0.000    0\n",
       "6  Steve Gajkowski          R     74    200  0.000    0\n",
       "7        Rick Schu          R     72    170  0.246   41\n",
       "8        Tom Brown          R     73    170  0.000    0\n",
       "9     Tom Browning          L     73    190  0.153    2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_left=baseball[baseball['handedness']=='L']\n",
    "baseball_right=baseball[baseball['handedness']=='R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               name handedness height weight    avg   HR\n",
       " 2      Philip Nastu          L     74    180  0.040    0\n",
       " 3        Kent Hrbek          L     76    200  0.282  293\n",
       " 9      Tom Browning          L     73    190  0.153    2\n",
       " 13        Tom Brown          L     70    168  0.265   64\n",
       " 15  Floyd Bannister          L     73    190  0.175    0\n",
       " 19        Joe Nolan          L     71    175  0.263   27\n",
       " 21     George Young          L     72    185  0.000    0\n",
       " 23       Tim Talton          L     75    200  0.295    2\n",
       " 27       Russ Kerns          L     72    188  0.000    0\n",
       " 28      Chris Gwynn          L     72    200  0.261   17,\n",
       "                name handedness height weight    avg   HR\n",
       " 0      Brandon Hyde          R     75    210  0.000    0\n",
       " 1       Carey Selph          R     69    175  0.277    0\n",
       " 4       Bill Risley          R     74    215  0.000    0\n",
       " 6   Steve Gajkowski          R     74    200  0.000    0\n",
       " 7         Rick Schu          R     72    170  0.246   41\n",
       " 8         Tom Brown          R     73    170  0.000    0\n",
       " 10      Tommy Brown          R     73    170  0.241   31\n",
       " 12         Joe Burg          R     70    143  0.326    0\n",
       " 14    Terry McGriff          R     74    190  0.206    3\n",
       " 16  Richard Hidalgo          R     75    220  0.269  171)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_left.head(10), baseball_right.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "welcht=scipy.stats.ttest_ind(baseball_left['avg'], baseball_right['avg'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=9.935702226242094, pvalue=3.810274225888738e-23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "welcht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the pvalue. If pvalue<=0.05 we reject the null hypothesis\n",
    "if welcht[1]<=0.05:\n",
    "    result=(False, welcht)\n",
    "# If pvalue>0.05 we do not have strong evidence to reject the null hypothesis\n",
    "else:\n",
    "    result=(True, welcht)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " Ttest_indResult(statistic=9.935702226242094, pvalue=3.810274225888738e-23))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SINCE WE GOT A P-VALUE MUCH MORE LESS THAN 0.05, WE STRONGLY REJECT THE NULL HYPOTHESIS, WHICH MEANS THAT\n",
    "# THE MEAN OF LEFT HAND BATTERS IS NOT EQUAL THAN RIGHT HAND BATTERS\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### What about Non-Normal Distributions\n",
    "\n",
    "The thing is that, for T-test we asume that the data is normal distributed, but in the reality many systems are not normal distributed. Therefore there are other types of statistical test for those other systems.\n",
    "\n",
    "Firts of all, we should check whether our data is normal distributed or not. That can be superfitial checked by ploting the histogram of the data and ask if that looks like a bell curve.\n",
    "\n",
    "There are some statistical test that we can use to measure the likelihood that a sample is drawn from a normally distributed population. One such test is the shapiro-wilk test.\n",
    "\n",
    "#### Shapiro-Wilk Test in Python\n",
    "\n",
    "Easy to implement in Python:\n",
    "\n",
    "w,p = scipy.stats.shapiro(data)\n",
    "\n",
    "This function receives as parameter the whole set of data and returns two values, the first is the Shapiro-Wilk test statistics and the second is the P-value which should be interpreted in the same way we would interpret it for the T-test. That is, given the Null Hypothesis that this data is drawn by from a normal distribution, what is the likelihood that we would observe a value of W that was at least as extreme as the one that we see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Parametric Test\n",
    "is a statistical test that does not assume our data is drawn from any particular underlying probability distribution.\n",
    "\n",
    "#### Mann-Whitney U Test\n",
    "the Null Hypothesis of this test is that two populations are the same. Basically, whether or not two samples come from the same population.\n",
    "\n",
    "Also easy to implement in Python:\n",
    "\n",
    "u,p = scipy.stats.mannwhitneyu(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DIfferent Types of Machine Learning ALgorithms\n",
    "\n",
    "There are many types, two common ones are Supevised and Unsupervised Learning.\n",
    "Machine learning involves the generation of some type of model, depending in the problem you want to solve. We will feed data into this model and then try to make prediccions.\n",
    "\n",
    "In Supervised learning there are labeled inputs that we train our model on. Training our model means simply teaching the model what the correct answer looks like. \n",
    "So for example you want to know if an email is spam or not. You have some emails (training examples) already that you know whether or not they are spam. So you train your model with the training example and it will then have the capability to decide whether a new email is spam or not, by looking at parameters like the content, if it has attached files, etc. In conclusion, you train your model with some initial data (called training examples), and depending on some characteristics of these initial data, your model will then take decisions for the future ones.\n",
    "\n",
    "In Unsupervised learning you do not have such training examples, instead you have a bunch of unlabeled data points and we try to understand the structure of the data, often by clustering similar data points together.\n",
    "SO for example if you feed an unsupervised learning algorithm with a bunch of fotos, it might split the fotos into groups, let's say photos of people, of animals, of buildings, without being told a priori what those groups should be. It might not known that the groups are people, animals or buildings, but it can tell that these distinct groups exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "def compute_cost(features, values, theta):\n",
    "    \"\"\"\n",
    "    Compute the cost of a list of parameters, theta, given a list of features \n",
    "    (input data points) and values (output data points).\n",
    "    \"\"\"\n",
    "    m = len(values)\n",
    "    sum_of_square_errors = numpy.square(numpy.dot(features, theta) - values).sum()\n",
    "    cost = sum_of_square_errors / (2*m)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
    "    \"\"\"\n",
    "    Perform gradient descent given a data set with an arbitrary number of features.\n",
    "    \"\"\"\n",
    "\n",
    "    m=len(values)\n",
    "    cost_history = []\n",
    "    for i in range(num_iterations):\n",
    "        predicted_values = numpy.dot(features, theta)\n",
    "        theta = theta - alpha/m * numpy.dot((predicted_values - values), features)\n",
    "        \n",
    "        cost = compute_cost(features, values, theta)\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    return theta, pandas.Series(cost_history) # leave this line for the grader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you apply any method to predict some output given a set of values, you really want to check whether your model with its predictions are good enough; in other words we need some way to evaluate the effectiveness of our model. One way to do that is by using the Coefficient of Determination also called R-Squared, and it is defined as follows:\n",
    "\n",
    "#### Coefficient of Determination\n",
    "Given the following values:\n",
    "data = yi,...,yn    -    predictions = fi,...,fn     -     average of data = y^\n",
    "\n",
    "R^2 = 1 - sum(yi - fi)^2 / sum(yi - y^)^2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-dde607ddc995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'theta' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
